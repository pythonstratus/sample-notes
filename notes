# Get metrics after data processing
from datetime import datetime

def get_processing_metrics():
    # Get record counts
    metrics_df = spark.sql("""
        SELECT 
            'fpds.contract_data' as table_name,
            'fpds' as schema_name,
            COUNT(*) as total_records,
            SUM(CASE WHEN insert_date = current_date() THEN 1 ELSE 0 END) as new_records
        FROM fpds.contract_data
    """)
    
    return metrics_df.collect()[0]

def format_email_body():
    # Get metrics
    metrics = get_processing_metrics()
    
    # Format email body with HTML
    email_body = f"""
    <html>
    <body>
    <h2>FPDS Data Processing Job Completed Successfully</h2>
    <p>Job completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    
    <h3>Processing Metrics:</h3>
    <ul>
        <li>Schema Name: {metrics.schema_name}</li>
        <li>Table Name: {metrics.table_name}</li>
        <li>Total Records: {metrics.total_records:,}</li>
        <li>New Records Added Today: {metrics.new_records:,}</li>
    </ul>
    
    <p>For more details, please check the job logs in Databricks.</p>
    </body>
    </html>
    """
    return email_body

# Use in your notification settings
email_body = format_email_body()
dbutils.notebook.exit(email_body)
