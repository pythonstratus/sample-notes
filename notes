import pandas as pd

def compare_csv_columns(file1_path, file2_path):
    # Read both CSV files
    df_pg = pd.read_csv(file1_path)
    df_databricks = pd.read_csv(file2_path)
    
    # Get column names from both dataframes
    pg_columns = set(df_pg.columns)
    databricks_columns = set(df_databricks.columns)
    
    # Find missing columns in databricks
    missing_in_databricks = pg_columns - databricks_columns
    
    # Print results
    print("\nColumns present in PostgreSQL but missing in Databricks:")
    if missing_in_databricks:
        for col in sorted(missing_in_databricks):
            print(f"- {col}")
    else:
        print("No missing columns found!")
    
    # Additional information
    print(f"\nTotal columns in PostgreSQL: {len(pg_columns)}")
    print(f"Total columns in Databricks: {len(databricks_columns)}")
    
    # Optional: Show columns that exist in Databricks but not in PostgreSQL
    extra_in_databricks = databricks_columns - pg_columns
    if extra_in_databricks:
        print("\nColumns present in Databricks but not in PostgreSQL:")
        for col in sorted(extra_in_databricks):
            print(f"- {col}")

if __name__ == "__main__":
    # Replace these with your actual file paths
    pg_file = "fpds_pg.csv"
    databricks_file = "fpds_databricks.csv"
    
    try:
        compare_csv_columns(pg_file, databricks_file)
    except Exception as e:
        print(f"An error occurred: {str(e)}")
