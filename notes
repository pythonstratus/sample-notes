Try this explicit schema approach:

```python
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType

# Define schema
schema = StructType([
    StructField("file_name", StringType(), True),
    StructField("file_path", StringType(), True),
    StructField("number_of_rows_ingested", IntegerType(), True),
    StructField("number_of_columns", IntegerType(), True),
    StructField("process_date", TimestampType(), True),
    StructField("file_type", StringType(), True),
    StructField("file_process_state", StringType(), True)
])

# Create DataFrame with schema
metadata_df = spark.createDataFrame([(
    file_name,
    file_path,
    num_rows,
    num_columns,
    process_date,
    file_type,
    file_process_state
)], schema)
```
