-- Safety check: Enable cascading drops
SET spark.sql.legacy.allowNonEmptyLocationInTruncate = true;

-- Get list of all tables in the schema
-- Replace 'your_schema_name' with your actual schema name
SHOW TABLES IN your_schema_name;

-- Drop all tables in the schema
-- You'll need to replace 'your_schema_name' and run this for each table from the SHOW TABLES result
DROP TABLE IF EXISTS your_schema_name.table_name CASCADE;

-- Drop the schema itself
DROP SCHEMA IF EXISTS your_schema_name CASCADE;

-- Verify schema is dropped
SHOW SCHEMAS LIKE 'your_schema_name';


---- Python Version ----


# Get the schema name
schema_name = "your_schema_name"

# Get list of all tables in the schema
tables = spark.sql(f"SHOW TABLES IN {schema_name}").select("tableName").collect()

# Drop each table
for table in tables:
    table_name = table.tableName
    spark.sql(f"DROP TABLE IF EXISTS {schema_name}.{table_name} CASCADE")

# Drop the schema
spark.sql(f"DROP SCHEMA IF EXISTS {schema_name} CASCADE")
