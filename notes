import psycopg2
import os
import subprocess
from datetime import datetime
import logging
from concurrent.futures import ThreadPoolExecutor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FastPostgresExport:
    def __init__(self, db_params, table_name, partition_column, output_dir):
        self.db_params = db_params
        self.table_name = table_name
        self.partition_column = partition_column
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)

    def get_partition_ranges(self):
        """Get the partition ranges for parallel processing."""
        with psycopg2.connect(**self.db_params) as conn:
            with conn.cursor() as cur:
                cur.execute(f"""
                    SELECT MIN({self.partition_column}), 
                           MAX({self.partition_column})
                    FROM {self.table_name}
                """)
                min_val, max_val = cur.fetchone()
                
                # Get total rows to calculate partitions
                cur.execute(f"SELECT COUNT(*) FROM {self.table_name}")
                total_rows = cur.fetchone()[0]
                
                # Aim for ~100 million rows per partition
                rows_per_partition = 100000000
                num_partitions = max(1, total_rows // rows_per_partition)
                
        step = (max_val - min_val) / num_partitions
        ranges = [(min_val + (step * i), min_val + (step * (i + 1))) 
                 for i in range(num_partitions)]
        return ranges

    def export_partition(self, partition_range):
        """Export a partition using COPY command."""
        min_val, max_val = partition_range
        partition_id = f"{min_val:.0f}_{max_val:.0f}"
        output_file = os.path.join(self.output_dir, f"{self.table_name}_partition_{partition_id}.csv")
        
        try:
            # Construct COPY command
            copy_sql = f"""
                COPY (
                    SELECT *
                    FROM {self.table_name}
                    WHERE {self.partition_column} >= {min_val}
                    AND {self.partition_column} < {max_val}
                ) TO STDOUT WITH (FORMAT CSV, HEADER)
            """
            
            # Use psql command-line tool for maximum performance
            env = os.environ.copy()
            env['PGPASSWORD'] = self.db_params['password']
            
            psql_command = [
                'psql',
                '-h', self.db_params['host'],
                '-p', str(self.db_params['port']),
                '-U', self.db_params['user'],
                '-d', self.db_params['database'],
                '-c', copy_sql
            ]
            
            with open(output_file, 'w') as f:
                subprocess.run(psql_command, stdout=f, env=env, check=True)
            
            logger.info(f"Successfully exported partition {partition_id}")
            
        except Exception as e:
            logger.error(f"Error exporting partition {partition_id}: {str(e)}")
            raise

    def export_all(self, max_workers=4):
        """Export all partitions in parallel."""
        start_time = datetime.now()
        logger.info(f"Starting export of {self.table_name} at {start_time}")
        
        partition_ranges = self.get_partition_ranges()
        logger.info(f"Will create {len(partition_ranges)} partitions")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            list(executor.map(self.export_partition, partition_ranges))
        
        end_time = datetime.now()
        duration = end_time - start_time
        logger.info(f"Export completed in {duration}")

# Usage example
if __name__ == "__main__":
    db_params = {
        "host": "your_host",
        "database": "your_database",
        "user": "your_user",
        "password": "your_password",
        "port": 5432
    }
    
    exporter = FastPostgresExport(
        db_params=db_params,
        table_name="your_table",
        partition_column="id",  # or any other numeric column suitable for partitioning
        output_dir="csv_output"
    )
    
    exporter.export_all(max_workers=4)
