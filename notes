import psycopg2
import os
import subprocess
from datetime import datetime
import logging
from concurrent.futures import ThreadPoolExecutor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PostgresExport:
    def __init__(self, db_params, table_name, output_dir, rows_per_partition=10000000):
        self.db_params = db_params
        self.table_name = table_name
        self.output_dir = output_dir
        self.rows_per_partition = rows_per_partition
        os.makedirs(self.output_dir, exist_ok=True)

    def get_total_rows(self):
        with psycopg2.connect(**self.db_params) as conn:
            with conn.cursor() as cur:
                cur.execute(f"SELECT COUNT(*) FROM {self.table_name}")
                return cur.fetchone()[0]

    def export_partition(self, partition):
        start_offset, partition_id = partition
        output_file = os.path.join(self.output_dir, f"{self.table_name}_part_{partition_id}.csv")
        
        copy_sql = f"""
            COPY (
                SELECT * FROM {self.table_name}
                OFFSET {start_offset} 
                LIMIT {self.rows_per_partition}
            ) TO STDOUT WITH (FORMAT CSV, HEADER)
        """
        
        try:
            env = os.environ.copy()
            env['PGPASSWORD'] = self.db_params['password']
            
            psql_command = [
                'psql',
                '-h', self.db_params['host'],
                '-p', str(self.db_params['port']),
                '-U', self.db_params['user'],
                '-d', self.db_params['database'],
                '-c', copy_sql
            ]
            
            with open(output_file, 'w') as f:
                subprocess.run(psql_command, stdout=f, env=env, check=True)
            
            logger.info(f"Exported partition {partition_id}")
            
        except Exception as e:
            logger.error(f"Error exporting partition {partition_id}: {str(e)}")
            raise

    def export_all(self, max_workers=4):
        start_time = datetime.now()
        total_rows = self.get_total_rows()
        num_partitions = (total_rows + self.rows_per_partition - 1) // self.rows_per_partition
        
        partitions = [(i * self.rows_per_partition, i) for i in range(num_partitions)]
        
        logger.info(f"Starting export of {self.table_name}: {total_rows} rows in {num_partitions} partitions")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            list(executor.map(self.export_partition, partitions))
        
        logger.info(f"Export completed in {datetime.now() - start_time}")

if __name__ == "__main__":
    db_params = {
        "host": "127.0.0.1",  # or your actual host
        "database": "your_database",
        "user": "your_user",
        "password": "your_password",
        "port": 5432
    }
    
    exporter = PostgresExport(
        db_params=db_params,
        table_name="your_table",
        output_dir="csv_output"
    )
    
    exporter.export_all(max_workers=4)
