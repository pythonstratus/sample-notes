from pyspark.sql.functions import col, lit
from pyspark.sql.types import StringType

def get_safe_columns(df, column_paths):
    available_columns = set(df.columns)
    safe_cols = []
    
    for col_path, alias_name in column_paths:
        try:
            if df.select(col_path).columns[0] in available_columns:
                # Explicitly cast to StringType()
                safe_cols.append(col(col_path).cast(StringType()).alias(alias_name))
            else:
                safe_cols.append(lit(None).cast(StringType()).alias(alias_name))
        except:
            safe_cols.append(lit(None).cast(StringType()).alias(alias_name))
    
    return safe_cols

column_paths = [
    ("ns0:content.ns1:award.ns1:placeOfPerformance.ns1:placeOfPerformanceCongressionalDistrict", "congressional_district"),
    ("ns0:content.ns1:award.ns1:contractData.ns1:contingencyHumanitarianPeacekeepingOperation._value", "peace_keeping_op"),
    ("ns0:content.ns1:award.ns1:productOrServiceInformation.ns1:contractBundling._value", "contract_bundling"),
    ("ns0:content.ns1:award.ns1:vendor.ns1:vendorSiteDetails.ns1:vendorOrganizationFactors.ns1:countryOfIncorporation", "country_of_incorporation"),
    ("ns0:content.ns1:award.ns1:relevantContractDates.ns1:currentCompletionDate", "completion_date"),
    ("ns0:content.ns1:award.ns1:competition.ns1:fedBizOpps._value", "fed_biz_opps"),
    ("ns0:content.ns1:award.ns1:contractMarketingData.ns1:feePaidForUseOfService", "fee_paid"),
    ("ns0:content.ns1:award.ns1:competition.ns1:idvNumberOfOffersReceived", "idv_number_of_offers"),
    ("ns0:content.ns1:award.ns1:productOrServiceInformation.ns1:informationTechnologyCommercialItemCategory", "it_commercial_category")
]

# Read the XML file
contract_df_3 = spark.read \
    .format("xml") \
    .option("rootTag", "feed") \
    .option("rowTag", "ns0:entry") \
    .option("valueTag", "_value") \
    .option("attributePrefix", "_") \
    .option("mode", "PERMISSIVE") \
    .load("/Volumes/staging/fpds_raw/landing/fpds_output_2025-01-03.xml")

# Cache the dataframe to improve performance
contract_df_3.cache()

# Process the dataframe with explicit schema casting
processed_df_3 = contract_df_3.select(get_safe_columns(contract_df_3, column_paths))

# Show the results
display(processed_df_3.head(100))
