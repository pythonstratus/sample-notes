from pyspark.sql import SparkSession
import csv
from datetime import datetime

def generate_access_control_report():
    spark = SparkSession.builder.getOrCreate()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"access_control_report_{timestamp}.csv"
    
    try:
        with open(filename, 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            
            # Write headers
            writer.writerow(['Securable Type', 'Securable Name', 'Principal Name', 'Action Type', 'Inherited'])
            
            # Get permissions for catalog
            writer.writerow(['=' * 20] * 5)  # Separator
            writer.writerow(['CATALOG PERMISSIONS'] + [''] * 4)
            writer.writerow(['=' * 20] * 5)  # Separator
            
            catalog_perms = spark.sql("SHOW GRANT ON CATALOG staging").collect()
            for perm in catalog_perms:
                writer.writerow([
                    'CATALOG',
                    'staging',
                    perm.principal,
                    perm.action_type,
                    perm.inherited
                ])
            
            writer.writerow([])  # Blank line
            
            # Get permissions for schema
            writer.writerow(['=' * 20] * 5)  # Separator
            writer.writerow(['SCHEMA PERMISSIONS'] + [''] * 4)
            writer.writerow(['=' * 20] * 5)  # Separator
            
            schema_perms = spark.sql("SHOW GRANT ON SCHEMA staging.bk_mpo").collect()
            for perm in schema_perms:
                writer.writerow([
                    'SCHEMA',
                    'staging.bk_mpo',
                    perm.principal,
                    perm.action_type,
                    perm.inherited
                ])
            
            writer.writerow([])  # Blank line
            
            # Get permissions for each table
            writer.writerow(['=' * 20] * 5)  # Separator
            writer.writerow(['TABLE PERMISSIONS'] + [''] * 4)
            writer.writerow(['=' * 20] * 5)  # Separator
            
            tables = spark.sql("SHOW TABLES FROM staging.bk_mpo").collect()
            for table in tables:
                table_name = table.tableName
                table_perms = spark.sql(f"SHOW GRANT ON TABLE staging.bk_mpo.{table_name}").collect()
                
                writer.writerow([f'Permissions for table: {table_name}'] + [''] * 4)
                for perm in table_perms:
                    writer.writerow([
                        'TABLE',
                        f'staging.bk_mpo.{table_name}',
                        perm.principal,
                        perm.action_type,
                        perm.inherited
                    ])
                writer.writerow([])  # Blank line between tables
        
        print(f"Access Control report has been created: {filename}")
        print("You can open this file directly in Microsoft Excel or Word.")
                    
    except Exception as e:
        print(f"Error: {str(e)}")

if __name__ == "__main__":
    generate_access_control_report()
